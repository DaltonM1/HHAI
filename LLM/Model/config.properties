inference_address=http://0.0.0.0:8080
management_address=http://0.0.0.0:8081
metrics_address=http://0.0.0.0:8082
enable_envvars_config=true
batch_size=10
max_batch_delay=50
# If using GPUs, adjust accordingly
number_of_gpu=1
# For CPU optimization
cpu_launcher_enable=true
cpu_launcher_args=--use_logical_core
